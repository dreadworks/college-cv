\documentclass{report}

% \usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}

% fonts
\usepackage{geometry,amsmath,amsfonts,metalogo,hyperref,mdwlist,array,multicol,fontawesome,color}
\usepackage[default,osf]{sourcesanspro}
\usepackage[scaled=.95]{sourcecodepro}
\linespread{1.3}

% figures
\usepackage{subfig}
\usepackage{float}
\restylefloat{figure}

\usepackage{wrapfig}

\begin{document}


%
%   SHOW OFF
%


{\centering

  \begin{figure}
    \vspace{3cm}

    \centering
    \includegraphics[width=0.3\textwidth]{src/yield}

    \vspace{4cm}
  \end{figure}


  {\Huge\textbf{Yield Sign Detection}}
  \vspace{.4cm}

  Felix Hamann

  \vspace{.2cm}

  \today

}


%
%   CONTENT
%

\tableofcontents


\chapter{Introduction}

This document describes the implementation of a system to detect yield
signs from images.

{\color{red}{
    \begin{enumerate}
    \item \textit{Notation definitions}
      \begin{enumerate}
      \item \textit{Always height x width}
      \item \textit{For binary images: 1 corresponds to white}
      \item \textit{For every step in the pipeline there is 'source'
        and 'target'}
      \end{enumerate}
    \item \textit{Image test set}
    \item \textit{Requirements}
      \begin{enumerate}
      \item \textit{Changing light (night, day, dawn, dusk)}
      \item \textit{Image sizes}
      \item \textit{Performance}
      \end{enumerate}
    \end{enumerate}
}}


\pagebreak
\chapter{The filter pipeline}
...

\begin{enumerate}
\item Binarization

  \begin{enumerate}
  \item Red Amplification
  \item Binarization
  \end{enumerate}

\end{enumerate}


\section{Binarization}

The first step of the whole pipeline consists of extracting the red
color from the coloured input image \textit{source}. Thus a mapping
for each pixel from three dimensions to one dimension is
needed. Simply returning the red color component does not suffice, as
with larger values of the green and blue components the source color
either shifts towards yellow, magenta or white. A very simple method
that is used in this application takes the red component, optionally
amplifies it by some factor and substracts the green and blue
components values.

Let \( \Gamma = \{0, 1, ..., 255\} \) be all possible pixel values, \(
\delta \in \Gamma \) the threshold and \( \alpha \in \mathbb{R},
\alpha \geq 1 \) the factor for red amplification, then the pixel
written to the binarized image \textit{target} is:

\begin{equation}\label{eq:binarization}
  \begin{split}
    f & : \Gamma \times \Gamma \times \Gamma \to \mathbb{Z} \\
    f(r, g, b) & = \alpha r - (g + b) \\
    target(y, x) & =
    \begin{cases}
      1 & \quad \text{if } f(source(y, x)) > \delta \\
      0 & \quad \text{else}
    \end{cases}
  \end{split}
\end{equation}

This method has one drawback however. There is no distinction between
less saturated or darker shades of red and orange or magenta. This is
a result of not taking the distance between green and blue into
account. An example is depicted in Table
\ref{table:binarization}. More elaborate variations of this
calculation were tested (considering the ratio of red to all colors or
weighting by green-blue distance) but this did not increase the
overall quality of red detection. Actually, without constantly white
balancing the camera used for capturing, narrowing the range of red
would perform worse as the ambient light differs greatly over the
course of a day. The drawback of this approach are more falsely marked
areas of the image that have to be considered in all further steps.

\begin{table}
  \centering
  \begin{tabular}{c r r r r r}

    \textbf{Color} & \textbf{Red} & \textbf{Green} & \textbf{Blue} &
    \textbf{\textit{f(r, g, b)}} & \textbf{\textit{target(y, x)}} \\ \hline

    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_000000}} &   0 &   0 &   0 &    0 & 0 \\ \hline
    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_ffffff}} & 255 & 255 & 255 &  -51 & 0 \\ \hline
    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_00ff00}} &   0 & 255 &   0 & -255 & 0 \\ \hline
    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_0000ff}} &   0 &   0 & 255 & -255 & 0 \\ \hline
    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_ff0000}} & 255 &   0 &   0 &  459 & 1 \\ \hline
    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_ff8888}} & 255 & 125 & 125 &  209 & 1 \\ \hline
    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_ff8800}} & 255 & 125 &   0 &  334 & 1 \\ \hline
    \parbox[c]{1em}{\includegraphics[width=1em]{src/bin_ff0088}} & 255 &   0 & 126 &  334 & 1

  \end{tabular}
  \caption{Example results of function \textit{f} in
    \ref{eq:binarization} with \( \alpha=1.8, \delta=200 \). Note that
    the result is equivalent for light red, orange and magenta.}
  \label{table:binarization}
\end{table}

{\color{red}{\textit{Performance, Pictures}}}


\section{Morphological operations}

At this point of the pipeline, the \textit{source} image is a binary
image with all areas considered red marked true. The quality of the
image and found red areas depends greatly on a variety of factors. For
one the camera itself might introduce pixel errors to the picture,
resulting in falsely colored pixels (when the sensor is of inferior
quality or getting old) or blacked out areas (e.g. when the lens is
dirty). On the other hand the to-be-detected yield sign could be
dirty, altered by vandalism or simply reflect light which would
obscure its shape. As it is essential to expose the signs form for
best detection, some morphological operations may be applied for noise
removal.

The system implements two morphological operations that are separately
adjustable. These operations are called dilation and erosion. This is
called ``closing'' when combined. The purpose and functioning of these
algorithms are described below.


\subsection{Erosion and Dilation}

Main purpose of erosion is to remove white noise from the binary
image. For every pixel of the \textit{source} image, some range around
the pixel is considered. This range - as used the current
implementation - can be seen in \ref{eq:morph_mask} and is commonly
called ``structuring element'' \textit{S}. Now, for every pixel in the
\textit{source} image, the mask is applied and the target pixel is set
based on \ref{eq:morph_erosion}. Commonly speaking, the target pixel
is only set if all surrounding pixels masked by \textit{S} are also
set.

\begin{equation}\label{eq:morph_mask}
  S = \begin{bmatrix}

    -              & source(y-1, x) & -              \\
    source(y, x-1) & source(y, x)   & source(y, x+1) \\
    -              & source(y+1, x) & -

  \end{bmatrix}
\end{equation}

\begin{equation}\label{eq:morph_erosion}
  target(y, x) = 1 \iff \bigwedge_{s \in S} s \neq 0
\end{equation}

The functioning of the algorithm is depicted in
\ref{eq:morph_erosion-example}. Closed white components shrink by the
factor determined by the size of \textit{S}. Spurious grains of white
are eliminated completely. Thus the erosion is used to remove white
noise on black backgrounds such as the grain on the bottom right of
the example.

\begin{align}\label{eq:morph_erosion-example}
  source = \begin{bmatrix}
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 1 & 1 & 1 & 0 \\
    0 & 1 & 1 & 1 & 1 & 0 \\
    0 & 1 & 1 & 1 & 1 & 0 \\
    0 & 1 & 1 & 1 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1
  \end{bmatrix}
  & &
  \mapsto
  & &
  target = \begin{bmatrix}
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0
  \end{bmatrix}
\end{align}

The dilation operation alters the image in such way that closed white
forms expand by the factor determined by \textit{S}. Grains of black
are removed from white backgrounds. The algorithm itself works
analogous to the erosion algorithm but pixels in the target image are
set if any of the masked source pixels is white. The equation changes
accordingly and is defined in \ref{eq:morph_dilation}. An example is
given in \ref{eq:morph_dilation-example}. It can be observed that the
white form grows and the black grains inside that form vanish. Note
that the form is not smoothed and the cut propagates to the target.

\begin{equation}\label{eq:morph_dilation}
  target(y, x) = 1 \iff \bigvee_{s \in S} s \neq 0
\end{equation}

\begin{align}\label{eq:morph_dilation-example}
  source = \begin{bmatrix}
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 1 & 1 & 0 \\
    0 & 1 & 1 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 & 0
  \end{bmatrix}
  & &
  \mapsto
  & &
  target = \begin{bmatrix}
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 1 & 1 & 0 \\
    1 & 1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1 & 1 & 1
  \end{bmatrix}
\end{align}


\subsection{Opening and closing}

When erosion and dilation are combined they form an operation called
opening. This is due to the fact that if any forms are connected by
thinner areas this connection vanishes through erosion and the
original forms size is restored by dilating again afterwards. The
opposite effect occurs when first dilating and then eroding the
image. Here, thin connections are strengthened and connections between
forms may be established. This proves useful if a closed yield sign
shapes are required even if somebody took a pencil and drew over the
red area or light reflections break the red surface.


\subsection{Application to the system}

As stated before, closing is embedded to the system. Erosion nearly
never proved useful however. Most of the time the already small red
areas spanned by the yield signs are lost. This leads to never
detecting any yield signs that are far away. The number of iterations
are free parameters of the system and may be adjusted. Using one or
two iterations of dilation and one or zero iterations of erosion work
fairly well.

{\color{red}{Picture examples}}


\section{Component labeling}

This optional step tries to greatly reduce the impact of red image
areas that are not yield signs. The basic idea is that yield signs
enclose a white triangle and thus there are black areas enclosed by
closed white borders in the binary image. If all black areas are
labeled, the label with the most associated pixels must be the
background - assuming the yield sign is not the most prominent object
captured. All forms that do not enclose any area vanish that way,
greatly reducing the amount of considered objects. Because the
algorithm is defined for labeling white areas, the source image needs
to be inverted first.

The algorithm works by iterating the image from top-left, selecting
all white pixels and checking whether a new label needs to be
introduced or - if the neighbors are already labeled adopt that label
for the current pixel. Formally, given a mask \textit{M} and a set \(
L = \{1, 2, ... \} \) of unassigned labels, the target pixels value is
given by formula \ref{eq:label}. Because multiple values can be
returned by \textit{M}, another set \textit{E} is needed to store all
equivalents. After the first labeling step, the equivalents are
resolved by assigning the smallest label of possible candidates. This
algorithm is called two-pass algorithm and the form of \textit{L}
checks for 8-connectivity as all eight neighboring pixels are taken
into account.

\begin{equation}
  M = \begin{bmatrix}
    source(y-1, x-1) & source(y-1, x) & source(y-1, x+1) \\
    source(y, x-1)   & source(y, x)   & -
  \end{bmatrix}
\end{equation}


\begin{equation}\label{eq:label}
    target(y, x) =
    \begin{cases}
      min(L) \quad L = L \setminus l & \quad \text{if } \forall m \in M: m = 0 \\
      any(C) \quad C = \{ c | \forall c \in M \} \quad E = E \cup \{(m, n)\} & \quad \text{else}
    \end{cases}
\end{equation}

After labeling all distinct components of the image, the component
with the largest amount of associated pixels is set to white and the
image is again reversed. Although this step proves to be very
effective it has one big drawback: As soon as the detected yield sign
shape is not closed the whole detection system fails immediately. This
does not happen otherwise as even without a closed form, the other
edges are prominent enough to allow detection. Thus this step can be
optionally enabled or disabled.

{\color{red}{Picture examples}}


\section{Edge Detection}
{\color{red}{To be written}}


\section{Line Detection}
{\color{red}{To be written}}


\section{Yield Sign Detection}
{\color{red}{To be written}}


\subsection{Finding points of intersection}




\subsection{Determining Triangles}
{\color{red}{To be written}}


\subsection{Filtering Triangles for Yield Signs}
{\color{red}{To be written}}


\pagebreak
\chapter{Evaluation and Conclusion}


\end{document}
